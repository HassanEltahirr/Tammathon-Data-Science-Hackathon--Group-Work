{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-23T16:21:58.056839Z",
     "iopub.status.busy": "2025-04-23T16:21:58.056555Z",
     "iopub.status.idle": "2025-04-23T16:22:41.916291Z",
     "shell.execute_reply": "2025-04-23T16:22:41.915458Z",
     "shell.execute_reply.started": "2025-04-23T16:21:58.056814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T16:24:38.259846Z",
     "iopub.status.busy": "2025-04-23T16:24:38.259448Z",
     "iopub.status.idle": "2025-04-23T16:24:43.266032Z",
     "shell.execute_reply": "2025-04-23T16:24:43.265450Z",
     "shell.execute_reply.started": "2025-04-23T16:24:38.259814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Start the Ollama server as a background process\n",
    "process = subprocess.Popen(\"ollama serve\", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "print(\"Ollama server started in the background.\")\n",
    "# You might want to add a short sleep here to ensure the server starts up\n",
    "import time\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T16:37:15.035541Z",
     "iopub.status.busy": "2025-04-23T16:37:15.035254Z",
     "iopub.status.idle": "2025-04-23T16:37:18.793588Z",
     "shell.execute_reply": "2025-04-23T16:37:18.792492Z",
     "shell.execute_reply.started": "2025-04-23T16:37:15.035521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T16:24:45.928370Z",
     "iopub.status.busy": "2025-04-23T16:24:45.928105Z",
     "iopub.status.idle": "2025-04-23T16:24:51.831609Z",
     "shell.execute_reply": "2025-04-23T16:24:51.830762Z",
     "shell.execute_reply.started": "2025-04-23T16:24:45.928350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install ollama -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T16:43:23.698315Z",
     "iopub.status.busy": "2025-04-23T16:43:23.698016Z",
     "iopub.status.idle": "2025-04-23T16:43:33.841400Z",
     "shell.execute_reply": "2025-04-23T16:43:33.840251Z",
     "shell.execute_reply.started": "2025-04-23T16:43:23.698293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CELL 1: Start Ollama Server\n",
    "import os\n",
    "\n",
    "print(\"Starting Ollama server...\")\n",
    "# Run ollama serve in the background and redirect output to a log file\n",
    "os.system(\"ollama serve > ollama_server.log 2>&1 &\")\n",
    "print(\"Ollama server started in the background. Check ollama_server.log for status.\")\n",
    "\n",
    "# Give the server a moment to start up\n",
    "import time\n",
    "time.sleep(10) # Wait 10 seconds (adjust if needed)\n",
    "\n",
    "# Optional: Verify the server is running by listing models\n",
    "print(\"Checking available models...\")\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T16:43:33.843907Z",
     "iopub.status.busy": "2025-04-23T16:43:33.843584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import base64\n",
    "from pathlib import Path\n",
    "import nest_asyncio # Import nest_asyncio\n",
    "\n",
    "# --- Configuration ---\n",
    "# Replace with the identifier of your loaded model in Ollama\n",
    "MODEL_IDENTIFIER = \"/kaggle/input/customMode/qwen2-vl:7b\" # Example model identifier, replace with your actual model\n",
    "# Path to your input CSV file (must contain 'id' and 'file_name' columns)\n",
    "INPUT_CSV_PATH = \"/kaggle/input/tammathon-task-3/test.csv\"\n",
    "# Path where the output CSV with captions will be saved\n",
    "OUTPUT_CSV_PATH = \"/kaggle/working/output_with_captions.csv\"\n",
    "# Base folder where the images are located\n",
    "IMAGE_BASE_FOLDER = Path(\"/kaggle/input/tammathon-task-3/test/test\") # Use pathlib for better path handling\n",
    "# The text prompt to send along with each image\n",
    "PROMPT = \"Only answer with \\\"Car image with [elements]\\\" for all image upload using elements within ['broken lamp', 'crack', 'dent', 'flat tire', 'scratch', 'shattered glass'] ONLY. make sure the car image contains those features. Dont put dent on everything until you are sure.\\nie.\\\"Car image with flat tire, scratch.\\\"\"\n",
    "# Optional delay between API calls in seconds (to avoid overwhelming the server)\n",
    "DELAY_BETWEEN_REQUESTS_S = 1.0 # Delay in seconds\n",
    "\n",
    "# --- Helper Function to Read CSV ---\n",
    "def read_csv(file_path: str) -> tuple[list[dict], list[str]]:\n",
    "    data = []\n",
    "    fieldnames = []\n",
    "    try:\n",
    "        with open(file_path, mode='r', encoding='utf-8', newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            fieldnames = reader.fieldnames\n",
    "            if not fieldnames:\n",
    "                 raise ValueError(\"CSV file appears to be empty or missing headers.\")\n",
    "            if 'id' not in fieldnames or 'file_name' not in fieldnames:\n",
    "                raise ValueError(\"Input CSV must contain 'id' and 'file_name' columns.\")\n",
    "            for row in reader:\n",
    "                data.append(row)\n",
    "        if not data:\n",
    "             print(f\"Warning: CSV file '{file_path}' is empty or has no data rows after the header.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input CSV file not found at {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file {file_path}: {e}\")\n",
    "        raise\n",
    "    return data, fieldnames\n",
    "\n",
    "# --- Helper Function to Write CSV ---\n",
    "def write_csv(file_path: str, data: list[dict], fieldnames: list[str]):\n",
    "    try:\n",
    "        with open(file_path, mode='w', encoding='utf-8', newline='') as csvfile:\n",
    "            output_fieldnames = list(fieldnames)\n",
    "            if 'caption' not in output_fieldnames:\n",
    "                output_fieldnames.append('caption')\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=output_fieldnames, extrasaction='ignore')\n",
    "            writer.writeheader()\n",
    "            writer.writerows(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing CSV file {file_path}: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Main Asynchronous Script Logic ---\n",
    "async def main():\n",
    "    print(\"--- Starting Image Captioning Script (Python) ---\")\n",
    "    print(f\"Model Identifier: {MODEL_IDENTIFIER}\")\n",
    "    print(f\"Input CSV: {INPUT_CSV_PATH}\")\n",
    "    print(f\"Image Folder: {IMAGE_BASE_FOLDER}\")\n",
    "    print(f\"Output CSV: {OUTPUT_CSV_PATH}\")\n",
    "\n",
    "    if not os.path.exists(INPUT_CSV_PATH):\n",
    "        print(f\"Error: Input CSV not found at {INPUT_CSV_PATH}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    if not IMAGE_BASE_FOLDER.is_dir():\n",
    "        print(f\"Error: Image base folder not found or is not a directory at {IMAGE_BASE_FOLDER}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    data: list[dict] = []\n",
    "    original_fieldnames = []\n",
    "\n",
    "    try:\n",
    "        print(f\"Loading CSV file: {INPUT_CSV_PATH}...\")\n",
    "        data, original_fieldnames = read_csv(INPUT_CSV_PATH)\n",
    "        if not data:\n",
    "             print(\"CSV loading resulted in no data. Exiting.\")\n",
    "             return\n",
    "        if not original_fieldnames:\n",
    "             print(\"Could not read headers from CSV. Exiting.\")\n",
    "             return\n",
    "\n",
    "        print(f\"Found {len(data)} data rows in the CSV.\")\n",
    "\n",
    "        print(\"Initializing Ollama client...\")\n",
    "        client = ollama.AsyncClient()\n",
    "        print(\"Ollama client initialized.\")\n",
    "\n",
    "        total_rows = len(data)\n",
    "        print(\"Processing images...\")\n",
    "\n",
    "        for i, row in enumerate(data):\n",
    "            image_filename = str(row.get('file_name', '')).strip()\n",
    "            image_id = row.get('id', 'N/A')\n",
    "\n",
    "            if not image_filename:\n",
    "                print(f\"Skipping row {i + 1} (ID: {image_id}) due to missing 'file_name'.\")\n",
    "                row['caption'] = None\n",
    "                continue\n",
    "\n",
    "            full_image_path = IMAGE_BASE_FOLDER / image_filename\n",
    "            print(f\"Processing row {i + 1}/{total_rows}: id={image_id}, file={image_filename}\")\n",
    "            caption: str | None = None\n",
    "\n",
    "            if not full_image_path.is_file():\n",
    "                print(f\"  Warning: Image not found at {full_image_path}. Skipping.\")\n",
    "            else:\n",
    "                try:\n",
    "                    print(f\"  Sending request to Ollama for {image_filename}...\")\n",
    "                    response = await client.chat(\n",
    "                        model=MODEL_IDENTIFIER,\n",
    "                        messages=[\n",
    "                            {\n",
    "                                'role': 'user',\n",
    "                                'content': PROMPT,\n",
    "                                'images': [str(full_image_path)]\n",
    "                            }\n",
    "                        ]\n",
    "                    )\n",
    "                    print(\"  Received response from Ollama.\")\n",
    "\n",
    "                    if response and 'message' in response and 'content' in response['message']:\n",
    "                        caption = response['message']['content'].strip()\n",
    "                        print(f\"  Generated Caption (ID: {image_id}): {caption}\")\n",
    "                    else:\n",
    "                        print(f\"  Warning: Could not extract content from response for {image_filename}. Response: {response}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error processing {image_filename} with Ollama: {e}\")\n",
    "\n",
    "            row['caption'] = caption\n",
    "\n",
    "            if DELAY_BETWEEN_REQUESTS_S > 0 and i < total_rows - 1:\n",
    "                await asyncio.sleep(DELAY_BETWEEN_REQUESTS_S)\n",
    "\n",
    "        print(\"\\nFinished processing all images.\")\n",
    "        print(f\"Saving results to: {OUTPUT_CSV_PATH}...\")\n",
    "        write_csv(OUTPUT_CSV_PATH, data, original_fieldnames)\n",
    "        print(\"Output CSV saved successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- An unexpected error occurred in the main script ---\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    print(\"--- Script Finished ---\")\n",
    "\n",
    "# --- Run the main asynchronous function ---\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()\n",
    "    # Now run the main asynchronous function\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11647986,
     "sourceId": 97729,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
